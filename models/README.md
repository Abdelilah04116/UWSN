# ü§ñ Mod√®les Pr√©-entra√Æn√©s UWSN PPO

Ce dossier contient les mod√®les PPO entra√Æn√©s pour l'optimisation de routage UWSN.

## üìÅ Fichiers

- `ppo_uwsn.zip` - Mod√®le PPO principal (15 n≈ìuds, 1000m zone)
- `ppo_uwsn_quick.zip` - Mod√®le PPO rapide (8 n≈ìuds, 500m zone)
- `ppo_uwsn_best.zip` - Meilleur mod√®le (sauvegard√© automatiquement)

## üöÄ Utilisation

### Chargement d'un mod√®le
```python
from stable_baselines3 import PPO

# Charger le mod√®le
model = PPO.load("models/ppo_uwsn.zip")

# Utiliser pour la pr√©diction
action, _ = model.predict(observation, deterministic=True)
```

### Dans l'application Streamlit
1. Ouvrir l'interface web
2. Aller dans la sidebar "Mod√®le PPO"
3. Entrer le chemin du mod√®le
4. Cliquer sur "Charger le mod√®le"

## üìä Performance des mod√®les

### Mod√®le principal (ppo_uwsn.zip)
- **R√©seau** : 15 n≈ìuds, zone 1000m
- **Entra√Ænement** : 200,000 pas
- **Taux de succ√®s** : ~85%
- **√ânergie moyenne** : ~2.5 J
- **Latence moyenne** : ~0.8 s

### Mod√®le rapide (ppo_uwsn_quick.zip)
- **R√©seau** : 8 n≈ìuds, zone 500m
- **Entra√Ænement** : 10,000 pas
- **Taux de succ√®s** : ~70%
- **√ânergie moyenne** : ~1.2 J
- **Latence moyenne** : ~0.4 s

## üîß Entra√Ænement de nouveaux mod√®les

### Configuration par d√©faut
```python
from src.ppo_train import UWSNTrainer

trainer = UWSNTrainer(
    num_nodes=15,
    area_size=1000.0,
    depth_range=(-100, -10)
)

model = trainer.train(total_timesteps=200000)
```

### Configuration personnalis√©e
```python
# R√©seau plus grand
trainer = UWSNTrainer(
    num_nodes=25,
    area_size=1500.0,
    depth_range=(-150, -20)
)

# Entra√Ænement plus long
model = trainer.train(total_timesteps=500000)
```

## üìà √âvaluation des mod√®les

### M√©triques de base
```python
# √âvaluer le mod√®le
metrics = trainer.evaluate(num_episodes=100)

print(f"Taux de succ√®s: {metrics['success_rate']:.2%}")
print(f"√ânergie moyenne: {metrics['mean_energy']:.2f} J")
print(f"Latence moyenne: {metrics['mean_latency']:.3f} s")
```

### Comparaison avec baselines
```python
# Comparer avec d'autres m√©thodes
comparison = trainer.compare_with_baseline(num_episodes=100)

print("R√©sultats:")
for method, metrics in comparison.items():
    print(f"{method}: {metrics['success_rate']:.2%} succ√®s")
```

## üéØ Optimisation des mod√®les

### Hyperparam√®tres PPO
```python
# Configuration optimis√©e
model = PPO(
    "MlpPolicy",
    env,
    learning_rate=1e-4,      # Plus conservateur
    n_steps=4096,            # Plus de pas
    batch_size=128,          # Batch plus grand
    n_epochs=20,             # Plus d'√©poques
    gamma=0.995,             # Horizon plus long
    gae_lambda=0.98,         # Moins de biais
    clip_range=0.1,          # Plus conservateur
    ent_coef=0.005,          # Moins d'exploration
    vf_coef=0.25             # Moins de poids sur la valeur
)
```

### Architecture du r√©seau
```python
# R√©seau plus profond
policy_kwargs = dict(
    net_arch=[dict(pi=[512, 512, 256], vf=[512, 512, 256])],
    activation_fn=torch.nn.ReLU
)

model = PPO("MlpPolicy", env, policy_kwargs=policy_kwargs)
```

## üîÑ Mise √† jour des mod√®les

### Sauvegarde automatique
Les mod√®les sont sauvegard√©s automatiquement pendant l'entra√Ænement :
- Tous les 50,000 pas
- Meilleur mod√®le (√©valuation)
- Mod√®le final

### Sauvegarde manuelle
```python
# Sauvegarder le mod√®le
model.save("models/mon_modele_personnalise")

# Sauvegarder avec m√©tadonn√©es
trainer._save_metadata()
```

## üìä Monitoring de l'entra√Ænement

### TensorBoard
```bash
# Lancer TensorBoard
tensorboard --logdir=./tensorboard_logs/

# Ouvrir http://localhost:6006
```

### M√©triques personnalis√©es
```python
# Ajouter des m√©triques personnalis√©es
class CustomCallback(BaseCallback):
    def _on_step(self):
        # Votre logique de monitoring
        return True

model.learn(total_timesteps=100000, callback=CustomCallback())
```

## üêõ D√©pannage

### Probl√®mes courants

1. **Mod√®le ne charge pas**
   - V√©rifier le chemin du fichier
   - V√©rifier la version de stable-baselines3
   - V√©rifier la compatibilit√© PyTorch

2. **Performance d√©grad√©e**
   - V√©rifier la configuration du r√©seau
   - V√©rifier les param√®tres d'entra√Ænement
   - V√©rifier la fonction de r√©compense

3. **Erreurs de m√©moire**
   - R√©duire la taille du r√©seau
   - R√©duire le batch_size
   - Utiliser la sauvegarde fr√©quente

### Logs de d√©bogage
```python
import logging
logging.basicConfig(level=logging.DEBUG)

# Votre code d'entra√Ænement...
```

## üìö Ressources

- [Documentation Stable-Baselines3](https://stable-baselines3.readthedocs.io/)
- [Guide PPO](https://spinningup.openai.com/en/latest/algorithms/ppo.html)
- [Optimisation des hyperparam√®tres](https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html)

---

*Pour plus d'informations, consultez le README principal du projet.*
